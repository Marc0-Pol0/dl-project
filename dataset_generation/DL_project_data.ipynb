{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c888074a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "\n",
    "from theme_attention.rnd import marketsTool as tools\n",
    "\n",
    "import warnings\n",
    "\n",
    "from base.sql import factset as fs\n",
    "from theme_attention.pipeline import dbTool as dbt \n",
    "\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import utils\n",
    "import importlib \n",
    "importlib.reload(utils) \n",
    "\n",
    "import requests\n",
    "from io import StringIO\n",
    "import yfinance as yf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133e813",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Adjust Pandas display settings to show all rows and columns\n",
    "#pd.set_option('display.max_rows', None)  # Show all rows\n",
    "#pd.set_option('display.max_columns', None)  # Show all columns\n",
    "#pd.set_option('display.width', 1000)  # Adjust the width to fit the output\n",
    "\n",
    "# Reset Display Settings\n",
    "#pd.reset_option('display.max_rows')\n",
    "#pd.reset_option('display.max_columns')\n",
    "#pd.reset_option('display.width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe294982",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- TICKERS (initial idea, not used at the moment) ---\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "# Fetch HTML content\n",
    "html = requests.get(\n",
    "    \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\",\n",
    "    headers=headers\n",
    ").text\n",
    "\n",
    "# Read tables\n",
    "tables = pd.read_html(StringIO(html))\n",
    "sp500 = tables[1]\n",
    "\n",
    "# Extract raw tickers\n",
    "tickers_500 = sp500[\"Symbol\"].tolist()\n",
    "\n",
    "# Tickers of the top 20 companies by market capitalization in the S&P 500\n",
    "# If \"tickers_500\" is too big to process, use \"tickers_20\" instead\n",
    "tickers_20 = [\"NVDA\",\"AAPL\",\"MSFT\",\"AMZN\",\"GOOGL\",\"AVGO\",\"GOOG\",\"META\",\"TSLA\",\"BRK.B\",\"LLY\",\"JPM\",\"V\",\"XOM\",\"JNJ\",\"WMT\",\"NFLX\",\"MA\",\"ABBV\",\"COST\"]\n",
    "\n",
    "# Bloomberg tickers (US equities)\n",
    "bb_tickers = [\n",
    "    f\"{t.replace('.', '/').replace(':', '/').replace('-', '/')} US\"\n",
    "    for t in tickers_20\n",
    "]\n",
    "\n",
    "# Map Yahoo exchange codes to readable names\n",
    "yahoo_to_exch = {\n",
    "    \"NMS\": \"NASDAQ\",  \n",
    "    \"NGM\": \"NASDAQ\",\n",
    "    \"NGS\": \"NASDAQ\",\n",
    "    \"NSQ\": \"NASDAQ\",\n",
    "    \"NYQ\": \"NYSE\",    \n",
    "    \"NYS\": \"NYSE\",\n",
    "    \"PCX\": \"AMEX\",    \n",
    "}\n",
    "\n",
    "def get_exchange(symbol):\n",
    "    t = yf.Ticker(symbol)\n",
    "    ex = t.info.get(\"exchange\")  # e.g. \"NMS\", \"NYQ\"\n",
    "    if ex is None:\n",
    "        return \"UNKNOWN\"\n",
    "    return yahoo_to_exch.get(ex, ex)  # map if known, else keep raw\n",
    "\n",
    "# Build market tickers: EXCHANGE:SYMBOL (e.g. NASDAQ:AAPL)\n",
    "exchanges = [get_exchange(sym) for sym in tickers_20]\n",
    "mkt_tickers = [f\"{ex}:{sym}\" for ex, sym in zip(exchanges, tickers_20)]\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"symbol\": tickers_20,\n",
    "    \"bb_ticker\": bb_tickers,\n",
    "    \"mkt_ticker\": mkt_tickers\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f473f88",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Adjust the mkt_ticker for Berkshire Hathaway manually\n",
    "df.loc[df[\"symbol\"] == \"BRK.B\", \"mkt_ticker\"] = \"NYSE:BRK.B\"\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ccbf0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Call existing ticker mapping function to get fsym_id and other info\n",
    "mapT = fs.getFsymIDsFromBBTicker(bb_tickers)\n",
    "\n",
    "masterT = fs.getFactsetCoverage(mapT['fsym_id'].to_frame())\n",
    "masterT = masterT.merge(mapT, on='fsym_id')\n",
    "\n",
    "# Merge Bloomberg ticker, and FactSet ID into one DataFrame\n",
    "companiesDB = df[['bb_ticker', 'mkt_ticker']].merge(mapT, left_on='bb_ticker', right_on='bbg_ticker', how='left').merge(masterT, left_on='fsym_id', right_on='fsym_id', how='left')\n",
    "\n",
    "# Final \n",
    "companiesMapping = companiesDB[['bb_ticker', 'mkt_ticker', 'fsym_id', 'proper_name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "companiesMapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dff417",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# --- TICKERS ---\n",
    "# Region Codes (EOD Mapping)\n",
    "# US  -> United States\n",
    "# RDM -> Rest of Developed Markets (e.g., Europe, Japan, Australia, etc.)\n",
    "# EM  -> Emerging Markets (e.g., China, India, Brazil, etc.)\n",
    "\n",
    "fL = dbt.get_master_mapping_df(region=['US'])\n",
    "# len(fL[\"sub_industry\"].unique())\n",
    "fL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cb098f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert exit_date to datetime\n",
    "fL[\"exit_date\"] = pd.to_datetime(fL[\"exit_date\"], errors=\"coerce\")\n",
    "\n",
    "# Keep only rows where exit_date is in the future\n",
    "today = pd.Timestamp.today().normalize()\n",
    "mask_date = fL[\"exit_date\"] >= today\n",
    "\n",
    "# Apply filter\n",
    "fL_filtered = fL[mask_date].copy()\n",
    "\n",
    "fL_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ba3e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Keep only needed columns\n",
    "companiesMapping = fL_filtered[\n",
    "    ['fsym_id', 'proper_name', 'price_id', 'Code', 'bbg_ticker']\n",
    "].copy()\n",
    "\n",
    "companiesMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e517b430",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get market capitalizations of the companies\n",
    "preliminary_fsym_ids = companiesMapping['fsym_id'].unique().tolist()\n",
    "\n",
    "market_cap = fs.getFundamentals(preliminary_fsym_ids, 'ff_mkt_val', 0, datetime.today() - relativedelta(months=3) , datetime.today())\n",
    "\n",
    "market_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff1782",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Merge market capitalization into companiesMapping\n",
    "companiesMapping = companiesMapping.merge(\n",
    "    market_cap[['fsym_id', 'qf']],\n",
    "    on='fsym_id',\n",
    "    how='left'\n",
    ")\n",
    "companiesMapping = companiesMapping.rename(columns={'qf': 'mkt_cap'}).dropna()\n",
    "\n",
    "companiesMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f4aa33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "FILE_PATH = \"/home/azureuser/cloudfiles/code/Users/manuel.noseda/DL_project_news/WatchListNews_FULL_PERIOD.pkl\"\n",
    "\n",
    "with open(FILE_PATH, \"rb\") as f:\n",
    "    news_dict = pickle.load(f)\n",
    "\n",
    "news_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebcc639",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# keep only companies whose Code exists in news_dict\n",
    "companies_with_news = companiesMapping[\n",
    "    companiesMapping['Code'].isin(news_dict.keys())\n",
    "]\n",
    "\n",
    "# Get the top 20 companies by market capitalization (and drop the mkt_cap column which is no more needed for cleaner output)\n",
    "top500 = (\n",
    "    companies_with_news\n",
    "    .sort_values('mkt_cap', ascending=False)\n",
    "    .head(500)\n",
    "    .drop(columns='mkt_cap')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "top500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2fe3a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fsym_ids = top500['fsym_id'].dropna().tolist()\n",
    "price_ids = top500['price_id'].dropna().tolist()\n",
    "eod_codes = top500['Code'].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5d5f5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Build the IDdf exactly as getAdjustedPrices() expects\n",
    "IDdf = pd.DataFrame({\n",
    "    \"fsym_id\": fsym_ids,\n",
    "    \"price_id\": price_ids   \n",
    "})\n",
    "\n",
    "IDdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b944c13",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Format: year, month, day\n",
    "\n",
    "startDate = datetime(2024,10,1) \n",
    "endDate = datetime(2025,8,1)\n",
    "# Get raw prices\n",
    "df_prices = fs.getAdjustedPrices(IDdf, startDate, endDate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0236b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Select only needed columns from prices\n",
    "df_small = df_prices[[\"fsym_id\", \"date\", \"adj_price\", \"unadj_price\"]]\n",
    "\n",
    "# Build the final dictionary\n",
    "companies_dict = {}\n",
    "\n",
    "# Store companyMapping and prices for each fsym_id\n",
    "for fsym, grp in df_small.groupby(\"fsym_id\"):\n",
    "    companies_dict[fsym] = {\n",
    "        \"companyMapping\": top500[top500[\"fsym_id\"] == fsym].copy(),\n",
    "        \"prices\": grp.drop(columns=\"fsym_id\").reset_index(drop=True)\n",
    "    }\n",
    "\n",
    "# Access the DataFrame of prices for the first fsym_id\n",
    "first_id = fsym_ids[0]\n",
    "proper_name = companies_dict[first_id]['companyMapping']['proper_name'].iloc[0]\n",
    "print(f'Prices for company \"{proper_name}\":')\n",
    "companies_dict[first_id][\"prices\"]\n",
    "\n",
    "config_path = Path.cwd() / \"config\" / \"DL_project_config.yml\"\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2930f7be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fundamentals to keep\n",
    "fundamentals_keep = [\n",
    "    'eps_basic',\n",
    "    'eps_dil',\n",
    "    'assets',\n",
    "    'shldrs_eq',\n",
    "    'inven',\n",
    "    'cash_st',\n",
    "    'debt',\n",
    "    'net_debt',\n",
    "    'net_inc',\n",
    "    'oper_cf'\n",
    "]\n",
    "\n",
    "# Iterate over each fsym_id, fetch fundamentals, filter (drop those used for ratios), then store\n",
    "for fsym_id in fsym_ids:\n",
    "    # 1) Get full fundamentals dict for this fsym_id\n",
    "    fundamentals_raw = utils.get_fundamentals(fsym_id, startDate, endDate, config)\n",
    "\n",
    "    # 2) Keep only the desired keys\n",
    "    fundamentals_filtered = {\n",
    "        key: df.drop(columns=[\"fsym_id\"], errors=\"ignore\").reset_index(drop=True)\n",
    "        for key, df in fundamentals_raw.items()\n",
    "        if key in fundamentals_keep\n",
    "    }\n",
    "    \n",
    "    # 3) Ensure entry exists and assign filtered fundamentals\n",
    "    if fsym_id not in companies_dict:\n",
    "        companies_dict[fsym_id] = {}\n",
    "\n",
    "    companies_dict[fsym_id][\"fundamentals\"] = fundamentals_filtered\n",
    "\n",
    "# Access the DataFrame of fundamentals for the first fsym_id\n",
    "first_id = fsym_ids[0]\n",
    "proper_name = companies_dict[first_id]['companyMapping']['proper_name'].iloc[0]\n",
    "print(f'Fundamentals for company \"{proper_name}\":')\n",
    "companies_dict[first_id][\"fundamentals\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d847276",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over each fsym_id and compute ratios\n",
    "for fsym_id in fsym_ids:\n",
    "    df = utils.get_ratios(fsym_id, startDate, endDate, config)\n",
    "\n",
    "    # Convert index to a column named \"date\"\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Put \"date\" as the first column\n",
    "    cols = [\"date\"] + [c for c in df.columns if c != \"date\"]\n",
    "    df = df[cols]\n",
    "\n",
    "    companies_dict[fsym_id][\"ratios\"] = df\n",
    "\n",
    "# Access the DataFrame of ratios for the first fsym_id\n",
    "first_id = fsym_ids[0]\n",
    "proper_name = companies_dict[first_id]['companyMapping']['proper_name'].iloc[0]\n",
    "print(f'Ratios for company \"{proper_name}\":')\n",
    "companies_dict[first_id][\"ratios\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96960b81",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over each fsym_id and retrieve news\n",
    "for fsym_id in fsym_ids:\n",
    "\n",
    "    company_data = companies_dict[fsym_id]['companyMapping']\n",
    "    eod_code = company_data['Code'].iloc[0]\n",
    "\n",
    "    news = news_dict[eod_code]\n",
    "\n",
    "    companies_dict[fsym_id][\"news\"] = news\n",
    "\n",
    "# Access the DataFrame of news for the first fsym_id\n",
    "first_id = fsym_ids[0]\n",
    "proper_name = companies_dict[first_id]['companyMapping']['proper_name'].iloc[0]\n",
    "print(f'News for company \"{proper_name}\":')\n",
    "companies_dict[first_id][\"news\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6193f2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over each fsym_id and retrieve earning announcements dates \n",
    "for fsym_id in fsym_ids:\n",
    "\n",
    "    company_data = companies_dict[fsym_id]['companyMapping']\n",
    "    eod_code = company_data['Code'].iloc[0]\n",
    "    symbol = eod_code.split(\".\")[0]\n",
    "    ticker = yf.Ticker(symbol)\n",
    "\n",
    "    earnings = ticker.get_earnings_dates(limit=20)\n",
    "\n",
    "    if earnings is None or earnings.empty:\n",
    "        print(f\"No earnings data for {symbol}\")\n",
    "        continue\n",
    "\n",
    "    # Keep only earnings announcements\n",
    "    earnings = earnings[earnings[\"Event Type\"] == \"Earnings\"]\n",
    "\n",
    "    # Convert index to a column named \"Earnings Date\"\n",
    "    earnings = earnings.copy()\n",
    "    earnings[\"Earnings Date\"] = earnings.index\n",
    "    earnings = earnings.reset_index(drop=True)\n",
    "\n",
    "    # Put \"Earnings Date\" as the first column\n",
    "    cols = [\"Earnings Date\"] + [c for c in earnings.columns if c != \"Earnings Date\"]\n",
    "    earnings = earnings[cols]\n",
    "\n",
    "    companies_dict[fsym_id][\"earnings\"] = earnings\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90676a48",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Access the DataFrame of earnings for the first fsym_id (done separately to get the output if there are no earnings data for a company in the previous cell)\n",
    "first_id = fsym_ids[0]\n",
    "proper_name = companies_dict[first_id]['companyMapping']['proper_name'].iloc[0]\n",
    "print(f'Earnings for company \"{proper_name}\":')\n",
    "companies_dict[first_id][\"earnings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a36d583",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save the dictionary to a pickle file\n",
    "\n",
    "local_path = '/home/azureuser/cloudfiles/code/Users/manuel.noseda/temp'\n",
    "file_name_root = 'DL_dataset'\n",
    "\n",
    "# create full file path\n",
    "file_path = os.path.join(local_path, f\"{file_name_root}.pkl\")\n",
    "\n",
    "# save the dictionary\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(companies_dict, f)\n",
    "\n",
    "print(f\"File saved in: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8d1aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "DATASET STRUCTURE\n",
    "\n",
    "companies_dict\n",
    "│\n",
    "├── fsym_id_1\n",
    "│     ├── companyMapping     → DataFrame\n",
    "│     ├── prices             → DataFrame\n",
    "│     ├── fundamentals       → dict of DataFrames\n",
    "│     ├── ratios             → DataFrame\n",
    "│     ├── news               → DataFrame\n",
    "│     └── earnings           → DataFrame\n",
    "│\n",
    "├── fsym_id_2\n",
    "│     ├── companyMapping\n",
    "│     ├── prices\n",
    "│     ├── fundamentals\n",
    "│     ├── ratios\n",
    "│     ├── news\n",
    "│     └── earnings\n",
    "│\n",
    "└── ...\n",
    "\n",
    "companyMapping : DataFrame\n",
    "    ├── fsym_id\n",
    "    ├── proper_name\n",
    "    ├── price_id\n",
    "    ├── Code\n",
    "    └── bbg_ticker\n",
    "\n",
    "prices : DataFrame\n",
    "    ├── date          \n",
    "    ├── adj_price     \n",
    "    └── unadj_price  \n",
    "\n",
    "fundamentals: Dictionary\n",
    "    ├── eps_basic   → DataFrame\n",
    "    ├── eps_dil     → DataFrame\n",
    "    ├── assets      → DataFrame\n",
    "    ├── shldrs_eq   → DataFrame\n",
    "    ├── inven       → DataFrame\n",
    "    ├── cash_st     → DataFrame\n",
    "    ├── debt        → DataFrame\n",
    "    ├── net_debt    → DataFrame\n",
    "    ├── net_inc     → DataFrame\n",
    "    └── oper_cf     → DataFrame\n",
    "\n",
    "    Each of these DataFrames has the same structure: date | af | qf | saf/ltm\n",
    "\n",
    "ratios : DataFrame\n",
    "    ├── date\n",
    "    ├── Dividend_Yield\n",
    "    ├── Net_Margin\n",
    "    ├── Gross_Margin\n",
    "    ├── ROE\n",
    "    ├── ROA\n",
    "    └── Debt_to_Equity\n",
    "\n",
    "news : DataFrame\n",
    "    ├── id\n",
    "    ├── event_type\n",
    "    ├── event_time \n",
    "    ├── msh_ids\n",
    "    ├── event_data \n",
    "    └── tags\n",
    "\n",
    "earnings : DataFrame\n",
    "    ├── Earnings Date\n",
    "    ├── EPS Estimate\n",
    "    ├── Reported EPS\n",
    "    ├── Surprise(%)\n",
    "    └── Event Type\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
