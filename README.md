# DL Project: Predicting Earnings Announcement Day Direction

This project was developed as part of a Deep Learning course project. It focuses on predicting stock price reactions to earnings announcements by combining firm fundamentals, market data, and FinBERT-based news sentiment using deep learning models.

**Important note on data availability**  
Due to size constraints, some data files referenced in this repository are **not included on GitHub**. The complete dataset and intermediate files are available on the original **GitLab repository**: https://gitlab.ethz.ch/nsoldati/dl-project

---

## Overview
- **Task:** multi-class classification (Up / Neutral / Down stock price movement after an earnings announcement)
- **Dataset:** custom-built dataset of ~1,000 U.S. equity earnings announcements (Oct 2024 – Aug 2025, 500 companies), combining firm fundamentals, market prices, and FinBERT-based news sentiment over a 30-day pre-announcement window
- **Models:** Logistic Regression baseline, LSTM, and Transformer
- **Goal:** predict post-EA price movement
- **Metrics:** Accuracy, Precision, Macro-F1, and a custom cost metric that penalizes incorrect Up/Down predictions more heavily than Neutral errors

---

## Repository Structure

### Dataset generation
- `dataset_generation/`
  - `DL_project_data.ipynb` – Jupyter notebook used to build the custom dataset by aggregating firm fundamentals, market prices, and news sentiment
  - `DL_project_news.py` – merges previously downloaded news files (segmented by time periods and company batches) into a consolidated news dataset
  - `utils.py` – helper functions
  - `DL_project_config.yml` – configuration file for dataset construction

> **Note:** Dataset generation requires private API access and was executed on an external Azure VM. Paths, credentials, and raw data are not portable. The resulting data files are **not included in this GitHub repository**, but are available on GitLab.

### Source code
- `src/`
  - `data/`
    - `merge.py` – merge fundamentals, news sentiment, and stock values
    - `preprocess.py` – cleaning and alignment of raw data
    - `sentiment.py` – generation of FinBERT sentiment distributions
  - `figures/` – confusion matrices for all evaluated models
  - `models/`
    - `dataloaders.py` – dataloaders for training and testing
    - `model.py` – model definitions
    - `train.py` – training pipeline
  - `training/` – legacy experiments conducted during the project

### Data
- `data/`
  - `raw/` – raw dataset generated by the pipeline (**not included on GitHub**)
  - `processed/` – intermediate processed data (**partially included on GitHub**)
  - `trainable/` – cleaned and date-aligned data ready for training (**fully included on GitHub**)

➡️ All of the above data directories are present in the **GitLab repository**:  
https://gitlab.ethz.ch/nsoldati/dl-project

### Trained models
- `networks/`
  - `lstm.pth` – trained LSTM
  - `attention.pth` – trained Transformer
  - `logreg.joblib` – trained logistic regression
  - `lstm_nosent.pth` – LSTM without sentiment
  - `attention_nosent.pth` – Transformer without sentiment
  - `logreg_nosent.joblib` – logistic regression without sentiment

### Miscellaneous
- `tests/playground.py` – data inspection playground
- `requirements.txt` – dependencies
- `runner.sh` – script for training on the ETH student cluster
- `README.md` – this file

---

## Quickstart

1. **Create virtual environment** (optional)

2. **Install dependencies**  
   pip install -r requirements.txt

3. **Prepare data**  
   The dataset was generated offline using `dataset_generation/DL_project_data.ipynb` and saved as `DL_dataset.pkl`.  
   Due to size constraints, the raw and some of the processed data files are **not included in this GitHub repository**. They are available on the original GitLab repository:  
   https://gitlab.ethz.ch/nsoldati/dl-project

4. **Train**  
   Configure the model type and whether to use sentiment features in the `Config` class, then run:  
   python src/models/train.py  

   Trained model checkpoints are saved to `networks/`.  
   On the ETH student cluster, submit the job using:  
   sbatch runner.sh

5. **Evaluate**  
   Evaluation is run automatically after training. To evaluate an existing checkpoint without retraining, set `REDO_TRAINING_IF_EXISTS = false` in `Config` and select the desired model/sentiment settings. The models reported in the paper are:  
   `lstm.pth`, `lstm_nosent.pth`, `attention.pth`, `attention_nosent.pth`, `logreg.joblib`, `logreg_nosent.joblib`.

---

## Setup
**Requirements:**
- Python ≥ 3.9
- PyTorch (for LSTM and Transformer training)
- Hugging Face Transformers (for FinBERT sentiment features)
- scikit-learn and scipy (preprocessing and evaluation)
- Optional: CUDA-enabled GPU for faster training

---

## Data
- **Source:** `data/raw/DL_dataset.pkl`  
  This file is **not included in this GitHub repository** due to size constraints. The full raw and processed datasets are available on the original GitLab repository:  
  https://gitlab.ethz.ch/nsoldati/dl-project
- **Pipeline:** starting from `DL_dataset.pkl`, the preprocessing code in `src/data/` produces reproducible intermediate and final datasets.
- **Folder structure:**
  - `data/raw/` – raw dataset (`DL_dataset.pkl`), not included on GitHub
  - `data/processed/` – intermediate processed data
  - `data/trainable/` – final data used for model training
- **Preprocessing code:** `src/data/merge.py`, `src/data/preprocess.py`, `src/data/sentiment.py`

### Dataset schema (summary)
`DL_dataset.pkl` is a Python dictionary indexed by firm identifier.  
Each entry contains ticker mappings, prices, fundamentals, ratios, news articles, and earnings data stored as pandas DataFrames.  
See the final cell of `dataset_generation/DL_project_data.ipynb` for the full schema.

---

## Configuration
No centralized configuration system is used.  
Model architecture choices and preprocessing parameters are defined directly in the code. Key training options (model type, sentiment usage, early stopping, checkpoint reuse) are controlled via the `Config` class in `src/models/train.py`.

---

## Usage
**Training and evaluation:**  
Run `python src/models/train.py` to preprocess data (if needed), train the selected model, and evaluate it.

**Inference:**  
No standalone inference script is provided; predictions are generated as part of the training and evaluation pipeline.

---

## Reproducibility
- **Hardware:** runs on GPU if CUDA is available, on MPS on macOS if available, and on CPU otherwise.
- **Data:** results are reproducible starting from `data/raw/DL_dataset.pkl` (dataset generation itself is not reproducible).
- **Steps:**
  1. Preprocess data
  2. Train model
  3. Run evaluation

---

## Results
- **Saved outputs:** best-performing model checkpoints are stored in `networks/`.
- **Metrics:** classification metrics (accuracy, precision, recall, Macro-F1) and a custom cost metric are computed during evaluation.
- **Models evaluated:** Logistic Regression, LSTM, and Transformer.
- **Summary:** The LSTM achieves lower financial risk through conservative predictions, while the Transformer captures more volatile movements and attains a higher Macro-F1 score. The baseline performs poorly in terms of risk control, and sentiment features consistently improve stability and performance across models.

> Full experimental details and analysis are provided in the project report.

---

## Contributors
- Manuel Noseda  
- Nathan Soldati  
- Marco Paina

